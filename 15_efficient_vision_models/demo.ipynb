{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# üëÅÔ∏è Lecture 15: Efficient Vision Models - Complete Demo\n", "\n", "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gaurav-redhat/efficientml_course/blob/main/15_efficient_vision_models/demo.ipynb)\n", "\n", "## What You'll Learn\n", "- Depthwise separable convolutions\n", "- MobileNet architecture design\n", "- EfficientNet compound scaling\n", "- FLOPs vs accuracy trade-offs"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install torch torchvision matplotlib numpy -q\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "\n", "torch.manual_seed(42)\n", "print('Ready for Efficient Vision Models!')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 1: Standard vs Depthwise Separable Convolution"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def conv_flops(in_ch, out_ch, kernel_size, h, w):\n", "    \"\"\"FLOPs for standard convolution.\"\"\"\n", "    return 2 * in_ch * out_ch * kernel_size * kernel_size * h * w\n", "\n", "def depthwise_separable_flops(in_ch, out_ch, kernel_size, h, w):\n", "    \"\"\"FLOPs for depthwise separable convolution.\"\"\"\n", "    # Depthwise: each channel separately\n", "    depthwise = 2 * in_ch * kernel_size * kernel_size * h * w\n", "    # Pointwise: 1√ó1 conv to mix channels\n", "    pointwise = 2 * in_ch * out_ch * h * w\n", "    return depthwise + pointwise\n", "\n", "# Compare\n", "in_ch, out_ch = 256, 256\n", "kernel_size = 3\n", "h, w = 56, 56\n", "\n", "standard = conv_flops(in_ch, out_ch, kernel_size, h, w)\n", "separable = depthwise_separable_flops(in_ch, out_ch, kernel_size, h, w)\n", "\n", "print('üìä CONVOLUTION COMPARISON')\n", "print('=' * 60)\n", "print(f'Input: {in_ch} channels, {h}√ó{w}, kernel {kernel_size}√ó{kernel_size}')\n", "print(f'\\n{\"Type\":<25} {\"FLOPs\":<20} {\"Relative\":<15}')\n", "print('-' * 60)\n", "print(f'{\"Standard Conv\":<25} {standard/1e6:>15.1f}M  {1.0:>12.1f}x')\n", "print(f'{\"Depthwise Separable\":<25} {separable/1e6:>15.1f}M  {separable/standard:>12.2f}x')\n", "print(f'\\nüí° Savings: {standard/separable:.1f}x fewer FLOPs!')"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Implement and visualize\n", "class StandardConv(nn.Module):\n", "    def __init__(self, in_ch, out_ch, kernel_size=3):\n", "        super().__init__()\n", "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size, padding=1)\n", "    \n", "    def forward(self, x):\n", "        return F.relu(self.conv(x))\n", "\n", "class DepthwiseSeparableConv(nn.Module):\n", "    def __init__(self, in_ch, out_ch, kernel_size=3):\n", "        super().__init__()\n", "        # Depthwise: each channel separately\n", "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size, \n", "                                    padding=1, groups=in_ch)\n", "        # Pointwise: 1√ó1 to mix channels\n", "        self.pointwise = nn.Conv2d(in_ch, out_ch, 1)\n", "    \n", "    def forward(self, x):\n", "        x = F.relu(self.depthwise(x))\n", "        return F.relu(self.pointwise(x))\n", "\n", "# Compare parameters\n", "std_conv = StandardConv(256, 256)\n", "ds_conv = DepthwiseSeparableConv(256, 256)\n", "\n", "std_params = sum(p.numel() for p in std_conv.parameters())\n", "ds_params = sum(p.numel() for p in ds_conv.parameters())\n", "\n", "print(f'\\nüìä PARAMETER COMPARISON')\n", "print(f'Standard Conv: {std_params:,} parameters')\n", "print(f'Depthwise Separable: {ds_params:,} parameters')\n", "print(f'Savings: {std_params/ds_params:.1f}x fewer parameters')"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize depthwise separable\n", "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n", "\n", "# Standard convolution\n", "ax = axes[0]\n", "ax.imshow(np.random.rand(3, 3, 4, 4).mean(axis=(2,3)), cmap='Blues')\n", "ax.set_title('Standard Conv\\n(All channels mixed)', fontsize=12)\n", "ax.axis('off')\n", "\n", "# Depthwise\n", "ax = axes[1]\n", "ax.imshow(np.eye(3), cmap='Greens')\n", "ax.set_title('Depthwise Conv\\n(Per-channel filtering)', fontsize=12)\n", "ax.axis('off')\n", "\n", "# Pointwise\n", "ax = axes[2]\n", "ax.imshow(np.random.rand(3, 3), cmap='Oranges')\n", "ax.set_title('Pointwise Conv (1√ó1)\\n(Channel mixing)', fontsize=12)\n", "ax.axis('off')\n", "\n", "plt.suptitle('üìä Depthwise Separable = Depthwise + Pointwise', fontsize=14)\n", "plt.tight_layout()\n", "plt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 2: MobileNet Architecture"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class InvertedResidual(nn.Module):\n", "    \"\"\"\n", "    MobileNetV2 Inverted Residual Block.\n", "    \n", "    Key innovation: Expand ‚Üí Depthwise ‚Üí Project\n", "    (Opposite of standard residual: narrow ‚Üí wide ‚Üí narrow)\n", "    \"\"\"\n", "    def __init__(self, in_ch, out_ch, stride=1, expand_ratio=6):\n", "        super().__init__()\n", "        hidden_ch = in_ch * expand_ratio\n", "        self.use_residual = (stride == 1 and in_ch == out_ch)\n", "        \n", "        layers = []\n", "        \n", "        # Expand (1√ó1 conv)\n", "        if expand_ratio != 1:\n", "            layers.extend([\n", "                nn.Conv2d(in_ch, hidden_ch, 1, bias=False),\n", "                nn.BatchNorm2d(hidden_ch),\n", "                nn.ReLU6()\n", "            ])\n", "        \n", "        # Depthwise (3√ó3 conv)\n", "        layers.extend([\n", "            nn.Conv2d(hidden_ch, hidden_ch, 3, stride, 1, \n", "                      groups=hidden_ch, bias=False),\n", "            nn.BatchNorm2d(hidden_ch),\n", "            nn.ReLU6()\n", "        ])\n", "        \n", "        # Project (1√ó1 conv, no activation!)\n", "        layers.extend([\n", "            nn.Conv2d(hidden_ch, out_ch, 1, bias=False),\n", "            nn.BatchNorm2d(out_ch)\n", "        ])\n", "        \n", "        self.conv = nn.Sequential(*layers)\n", "    \n", "    def forward(self, x):\n", "        if self.use_residual:\n", "            return x + self.conv(x)\n", "        return self.conv(x)\n", "\n", "# Test block\n", "block = InvertedResidual(32, 64, stride=2, expand_ratio=6)\n", "x = torch.randn(1, 32, 56, 56)\n", "out = block(x)\n", "\n", "print('üìä INVERTED RESIDUAL BLOCK')\n", "print('=' * 50)\n", "print(f'Input: {x.shape}')\n", "print(f'Output: {out.shape}')\n", "print(f'Parameters: {sum(p.numel() for p in block.parameters()):,}')\n", "\n", "print('\\nüîπ Architecture:')\n", "print('   Input (32ch) ‚Üí Expand 6√ó (192ch) ‚Üí Depthwise ‚Üí Project (64ch)')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 3: EfficientNet Compound Scaling"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def efficientnet_scaling(phi):\n", "    \"\"\"\n", "    EfficientNet compound scaling.\n", "    \n", "    Given a base network (B0), scale all dimensions together:\n", "    - Depth (d): Number of layers\n", "    - Width (w): Number of channels\n", "    - Resolution (r): Input image size\n", "    \n", "    Constraint: d √ó w¬≤ √ó r¬≤ ‚âà 2^phi (FLOPs increase by 2^phi)\n", "    \"\"\"\n", "    # EfficientNet scaling coefficients\n", "    alpha = 1.2   # Depth\n", "    beta = 1.1    # Width\n", "    gamma = 1.15  # Resolution\n", "    \n", "    d = alpha ** phi\n", "    w = beta ** phi\n", "    r = gamma ** phi\n", "    \n", "    return d, w, r\n", "\n", "# EfficientNet family\n", "efficientnets = {\n", "    'B0': {'phi': 0, 'resolution': 224, 'params': 5.3, 'flops': 0.39, 'top1': 77.1},\n", "    'B1': {'phi': 0.5, 'resolution': 240, 'params': 7.8, 'flops': 0.70, 'top1': 79.1},\n", "    'B2': {'phi': 1.0, 'resolution': 260, 'params': 9.2, 'flops': 1.0, 'top1': 80.1},\n", "    'B3': {'phi': 1.5, 'resolution': 300, 'params': 12, 'flops': 1.8, 'top1': 81.6},\n", "    'B4': {'phi': 2.0, 'resolution': 380, 'params': 19, 'flops': 4.2, 'top1': 82.9},\n", "    'B5': {'phi': 2.5, 'resolution': 456, 'params': 30, 'flops': 9.9, 'top1': 83.6},\n", "    'B6': {'phi': 3.0, 'resolution': 528, 'params': 43, 'flops': 19, 'top1': 84.0},\n", "    'B7': {'phi': 3.5, 'resolution': 600, 'params': 66, 'flops': 37, 'top1': 84.3},\n", "}\n", "\n", "print('üìä EFFICIENTNET FAMILY')\n", "print('=' * 70)\n", "print(f'{\"Model\":<8} {\"Resolution\":<12} {\"Params (M)\":<12} {\"FLOPs (B)\":<12} {\"Top-1 (%)\":<12}')\n", "print('-' * 70)\n", "\n", "for name, info in efficientnets.items():\n", "    print(f'{name:<8} {info[\"resolution\"]:<12} {info[\"params\"]:<12.1f} {info[\"flops\"]:<12.1f} {info[\"top1\"]:<12.1f}')"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize scaling\n", "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n", "\n", "models = list(efficientnets.keys())\n", "flops = [efficientnets[m]['flops'] for m in models]\n", "params = [efficientnets[m]['params'] for m in models]\n", "top1 = [efficientnets[m]['top1'] for m in models]\n", "\n", "# FLOPs vs Accuracy\n", "axes[0].plot(flops, top1, 'o-', color='#3b82f6', linewidth=2, markersize=10)\n", "for m, f, t in zip(models, flops, top1):\n", "    axes[0].annotate(m, (f, t), xytext=(5, 5), textcoords='offset points')\n", "axes[0].set_xlabel('FLOPs (B)')\n", "axes[0].set_ylabel('Top-1 Accuracy (%)')\n", "axes[0].set_title('Accuracy vs FLOPs')\n", "axes[0].grid(True, alpha=0.3)\n", "\n", "# Params vs Accuracy\n", "axes[1].plot(params, top1, 'o-', color='#22c55e', linewidth=2, markersize=10)\n", "for m, p, t in zip(models, params, top1):\n", "    axes[1].annotate(m, (p, t), xytext=(5, 5), textcoords='offset points')\n", "axes[1].set_xlabel('Parameters (M)')\n", "axes[1].set_ylabel('Top-1 Accuracy (%)')\n", "axes[1].set_title('Accuracy vs Parameters')\n", "axes[1].grid(True, alpha=0.3)\n", "\n", "# Scaling visualization\n", "phis = np.linspace(0, 3.5, 20)\n", "depths = [efficientnet_scaling(p)[0] for p in phis]\n", "widths = [efficientnet_scaling(p)[1] for p in phis]\n", "resolutions = [efficientnet_scaling(p)[2] for p in phis]\n", "\n", "axes[2].plot(phis, depths, label='Depth', linewidth=2)\n", "axes[2].plot(phis, widths, label='Width', linewidth=2)\n", "axes[2].plot(phis, resolutions, label='Resolution', linewidth=2)\n", "axes[2].set_xlabel('Compound Coefficient (œÜ)')\n", "axes[2].set_ylabel('Scaling Factor')\n", "axes[2].set_title('Compound Scaling')\n", "axes[2].legend()\n", "axes[2].grid(True, alpha=0.3)\n", "\n", "plt.tight_layout()\n", "plt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 4: Comparing Vision Architectures"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Architecture comparison\n", "architectures = {\n", "    'ResNet-50': {'params': 25.6, 'flops': 4.1, 'top1': 76.1},\n", "    'MobileNetV2': {'params': 3.4, 'flops': 0.30, 'top1': 72.0},\n", "    'MobileNetV3-L': {'params': 5.4, 'flops': 0.22, 'top1': 75.2},\n", "    'EfficientNet-B0': {'params': 5.3, 'flops': 0.39, 'top1': 77.1},\n", "    'EfficientNet-B4': {'params': 19, 'flops': 4.2, 'top1': 82.9},\n", "    'ViT-B/16': {'params': 86, 'flops': 17.6, 'top1': 77.9},\n", "    'DeiT-S': {'params': 22, 'flops': 4.6, 'top1': 79.8},\n", "}\n", "\n", "print('üìä VISION ARCHITECTURE COMPARISON')\n", "print('=' * 70)\n", "print(f'{\"Model\":<20} {\"Params (M)\":<12} {\"FLOPs (B)\":<12} {\"Top-1 (%)\":<12} {\"Acc/GFLOP\":<12}')\n", "print('-' * 70)\n", "\n", "for name, info in architectures.items():\n", "    efficiency = info['top1'] / info['flops']\n", "    print(f'{name:<20} {info[\"params\"]:<12.1f} {info[\"flops\"]:<12.1f} {info[\"top1\"]:<12.1f} {efficiency:<12.1f}')\n", "\n", "# Visualize\n", "fig, ax = plt.subplots(figsize=(12, 6))\n", "\n", "for name, info in architectures.items():\n", "    color = '#3b82f6' if 'ResNet' in name else ('#22c55e' if 'Mobile' in name else \n", "            '#f59e0b' if 'Efficient' in name else '#ef4444')\n", "    ax.scatter(info['flops'], info['top1'], s=info['params']*10, c=color, alpha=0.7)\n", "    ax.annotate(name, (info['flops'], info['top1']), xytext=(5, 5), \n", "                textcoords='offset points', fontsize=9)\n", "\n", "ax.set_xlabel('FLOPs (B)', fontsize=12)\n", "ax.set_ylabel('Top-1 Accuracy (%)', fontsize=12)\n", "ax.set_title('üìä Vision Models: Accuracy vs Efficiency\\n(Circle size = parameters)', fontsize=14)\n", "ax.grid(True, alpha=0.3)\n", "\n", "plt.tight_layout()\n", "plt.show()"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('üéØ KEY TAKEAWAYS')\n", "print('=' * 60)\n", "print('\\n1. Depthwise Separable Conv: ~9x fewer FLOPs')\n", "print('\\n2. Inverted Residual: Expand ‚Üí Depthwise ‚Üí Project')\n", "print('\\n3. EfficientNet: Compound scaling (depth √ó width √ó resolution)')\n", "print('\\n4. MobileNet: Best for mobile/edge deployment')\n", "print('\\n5. EfficientNet: Best accuracy/efficiency trade-off')\n", "print('\\n6. Vision Transformers: Need more data, less efficient')\n", "print('\\n' + '=' * 60)\n", "print('\\nüìö Next: Efficient LLMs!')"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8.0"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
