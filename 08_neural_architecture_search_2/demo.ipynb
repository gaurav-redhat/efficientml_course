{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# ðŸŽ¯ Lecture 8: Hardware-Aware NAS - Complete Demo\n", "\n", "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gaurav-redhat/efficientml_course/blob/main/08_neural_architecture_search_2/demo.ipynb)\n", "\n", "## What You'll Learn\n", "- Why hardware-aware NAS matters\n", "- Latency and FLOPs as constraints\n", "- Latency lookup tables\n", "- Multi-objective optimization"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install torch matplotlib numpy -q\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import time\n", "\n", "torch.manual_seed(42)\n", "print('Ready for Hardware-Aware NAS!')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 1: The Hardware Efficiency Gap\n", "\n", "**Problem**: Theoretical FLOPs â‰  Actual Latency\n", "\n", "Different operations have different hardware efficiency."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def measure_latency(op, x, num_runs=100):\n", "    \"\"\"Measure actual latency of an operation.\"\"\"\n", "    # Warmup\n", "    for _ in range(10):\n", "        _ = op(x)\n", "    \n", "    # Measure\n", "    start = time.time()\n", "    for _ in range(num_runs):\n", "        _ = op(x)\n", "    return (time.time() - start) / num_runs * 1000  # ms\n", "\n", "def count_flops(op, x):\n", "    \"\"\"Estimate FLOPs for common operations.\"\"\"\n", "    if isinstance(op, nn.Conv2d):\n", "        h, w = x.shape[2], x.shape[3]\n", "        out_h = h - op.kernel_size[0] + 1 + 2 * op.padding[0]\n", "        out_w = w - op.kernel_size[1] + 1 + 2 * op.padding[1]\n", "        return 2 * op.in_channels * op.out_channels * op.kernel_size[0] * op.kernel_size[1] * out_h * out_w\n", "    return 0\n", "\n", "# Compare different operations\n", "x = torch.randn(1, 64, 56, 56)\n", "\n", "operations = {\n", "    'Conv 3x3': nn.Conv2d(64, 64, 3, padding=1),\n", "    'Conv 5x5': nn.Conv2d(64, 64, 5, padding=2),\n", "    'Conv 7x7': nn.Conv2d(64, 64, 7, padding=3),\n", "    'Depthwise 3x3': nn.Conv2d(64, 64, 3, padding=1, groups=64),\n", "    'Depthwise 5x5': nn.Conv2d(64, 64, 5, padding=2, groups=64),\n", "    'Conv 1x1': nn.Conv2d(64, 64, 1),\n", "}\n", "\n", "print('ðŸ“Š FLOPS vs LATENCY COMPARISON')\n", "print('=' * 70)\n", "print(f'{\"Operation\":<20} {\"FLOPs (M)\":<15} {\"Latency (ms)\":<15} {\"FLOPS/ms\":<15}')\n", "print('-' * 70)\n", "\n", "results = []\n", "for name, op in operations.items():\n", "    flops = count_flops(op, x) / 1e6\n", "    latency = measure_latency(op, x)\n", "    efficiency = flops / latency if latency > 0 else 0\n", "    results.append({'name': name, 'flops': flops, 'latency': latency, 'efficiency': efficiency})\n", "    print(f'{name:<20} {flops:<15.2f} {latency:<15.3f} {efficiency:<15.2f}')\n", "\n", "# Visualize\n", "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n", "\n", "names = [r['name'] for r in results]\n", "flops = [r['flops'] for r in results]\n", "latencies = [r['latency'] for r in results]\n", "efficiencies = [r['efficiency'] for r in results]\n", "\n", "axes[0].barh(names, flops, color='#3b82f6')\n", "axes[0].set_xlabel('FLOPs (M)')\n", "axes[0].set_title('Theoretical Compute')\n", "\n", "axes[1].barh(names, latencies, color='#ef4444')\n", "axes[1].set_xlabel('Latency (ms)')\n", "axes[1].set_title('Actual Latency')\n", "\n", "axes[2].barh(names, efficiencies, color='#22c55e')\n", "axes[2].set_xlabel('FLOPS/ms')\n", "axes[2].set_title('Hardware Efficiency')\n", "\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "print('\\nðŸ’¡ Key Insight: Same FLOPs â‰  Same Latency!')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 2: Latency Lookup Tables"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LatencyTable:\n", "    \"\"\"\n", "    Pre-measured latency lookup table for different operations.\n", "    In practice, this is measured on the target hardware.\n", "    \"\"\"\n", "    def __init__(self):\n", "        # Latency in milliseconds for different (op, channels, resolution) combinations\n", "        # These are example values - real tables are measured on target hardware\n", "        self.table = {\n", "            # (operation, in_channels, out_channels, resolution)\n", "            ('conv3x3', 16, 16, 32): 0.05,\n", "            ('conv3x3', 16, 32, 32): 0.08,\n", "            ('conv3x3', 32, 32, 16): 0.06,\n", "            ('conv3x3', 32, 64, 16): 0.10,\n", "            ('conv3x3', 64, 64, 8): 0.08,\n", "            \n", "            ('conv5x5', 16, 16, 32): 0.12,\n", "            ('conv5x5', 16, 32, 32): 0.18,\n", "            ('conv5x5', 32, 32, 16): 0.14,\n", "            ('conv5x5', 32, 64, 16): 0.22,\n", "            ('conv5x5', 64, 64, 8): 0.18,\n", "            \n", "            ('sep_conv3x3', 16, 16, 32): 0.03,\n", "            ('sep_conv3x3', 16, 32, 32): 0.04,\n", "            ('sep_conv3x3', 32, 32, 16): 0.03,\n", "            ('sep_conv3x3', 32, 64, 16): 0.05,\n", "            ('sep_conv3x3', 64, 64, 8): 0.04,\n", "            \n", "            ('skip', 16, 16, 32): 0.001,\n", "            ('skip', 32, 32, 16): 0.001,\n", "            ('skip', 64, 64, 8): 0.001,\n", "        }\n", "    \n", "    def get_latency(self, op_name, in_ch, out_ch, resolution):\n", "        key = (op_name, in_ch, out_ch, resolution)\n", "        return self.table.get(key, 0.1)  # Default latency\n", "\n", "latency_table = LatencyTable()\n", "\n", "print('ðŸ“Š LATENCY LOOKUP TABLE')\n", "print('=' * 70)\n", "print(f'{\"Operation\":<15} {\"Channels\":<15} {\"Resolution\":<15} {\"Latency (ms)\":<15}')\n", "print('-' * 70)\n", "\n", "for key, latency in list(latency_table.table.items())[:10]:\n", "    op, in_ch, out_ch, res = key\n", "    print(f'{op:<15} {in_ch}â†’{out_ch:<10} {res}Ã—{res:<10} {latency:<15.3f}')\n", "\n", "print('\\nðŸ’¡ Lookup tables enable fast latency estimation during search!')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 3: Hardware-Aware Mixed Operation"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class HardwareAwareMixedOp(nn.Module):\n", "    \"\"\"\n", "    Mixed operation with latency awareness.\n", "    Includes latency cost in the architecture optimization.\n", "    \"\"\"\n", "    def __init__(self, in_channels, out_channels, resolution, latency_table):\n", "        super().__init__()\n", "        \n", "        self.in_channels = in_channels\n", "        self.out_channels = out_channels\n", "        self.resolution = resolution\n", "        self.latency_table = latency_table\n", "        \n", "        # Operations\n", "        self.ops = nn.ModuleDict({\n", "            'conv3x3': nn.Sequential(\n", "                nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n", "                nn.BatchNorm2d(out_channels), nn.ReLU()),\n", "            'conv5x5': nn.Sequential(\n", "                nn.Conv2d(in_channels, out_channels, 5, padding=2, bias=False),\n", "                nn.BatchNorm2d(out_channels), nn.ReLU()),\n", "            'sep_conv3x3': nn.Sequential(\n", "                nn.Conv2d(in_channels, in_channels, 3, padding=1, groups=in_channels, bias=False),\n", "                nn.Conv2d(in_channels, out_channels, 1, bias=False),\n", "                nn.BatchNorm2d(out_channels), nn.ReLU()),\n", "            'skip': nn.Identity() if in_channels == out_channels else \n", "                   nn.Conv2d(in_channels, out_channels, 1),\n", "        })\n", "        \n", "        self.op_names = list(self.ops.keys())\n", "        self.alpha = nn.Parameter(torch.zeros(len(self.op_names)))\n", "    \n", "    def forward(self, x):\n", "        weights = F.softmax(self.alpha, dim=0)\n", "        out = sum(w * self.ops[name](x) for w, name in zip(weights, self.op_names))\n", "        return out\n", "    \n", "    def get_latency(self):\n", "        \"\"\"Get expected latency based on current architecture weights.\"\"\"\n", "        weights = F.softmax(self.alpha, dim=0)\n", "        latency = 0\n", "        for w, name in zip(weights, self.op_names):\n", "            op_latency = self.latency_table.get_latency(\n", "                name, self.in_channels, self.out_channels, self.resolution)\n", "            latency += w * op_latency\n", "        return latency\n", "\n", "# Demo\n", "hw_mixed_op = HardwareAwareMixedOp(16, 16, 32, latency_table)\n", "\n", "print('ðŸ“Š HARDWARE-AWARE MIXED OPERATION')\n", "print('=' * 50)\n", "print('\\nOperation latencies:')\n", "for name in hw_mixed_op.op_names:\n", "    lat = latency_table.get_latency(name, 16, 16, 32)\n", "    print(f'  {name:<15}: {lat:.3f} ms')\n", "\n", "print(f'\\nExpected latency: {hw_mixed_op.get_latency().item():.3f} ms')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 4: Latency-Constrained NAS"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LatencyAwareSupernet(nn.Module):\n", "    \"\"\"Supernet with latency constraints.\"\"\"\n", "    def __init__(self, latency_table, num_classes=10):\n", "        super().__init__()\n", "        self.latency_table = latency_table\n", "        \n", "        self.stem = nn.Sequential(\n", "            nn.Conv2d(3, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU())\n", "        \n", "        # Searchable layers with different resolutions\n", "        self.layer1 = HardwareAwareMixedOp(16, 16, 32, latency_table)\n", "        self.layer2 = HardwareAwareMixedOp(16, 32, 16, latency_table)\n", "        self.layer3 = HardwareAwareMixedOp(32, 64, 8, latency_table)\n", "        \n", "        self.pool1 = nn.MaxPool2d(2)\n", "        self.pool2 = nn.MaxPool2d(2)\n", "        \n", "        self.gap = nn.AdaptiveAvgPool2d(1)\n", "        self.fc = nn.Linear(64, num_classes)\n", "    \n", "    def forward(self, x):\n", "        x = self.stem(x)\n", "        x = self.layer1(x)\n", "        x = self.pool1(x)\n", "        x = self.layer2(x)\n", "        x = self.pool2(x)\n", "        x = self.layer3(x)\n", "        x = self.gap(x).flatten(1)\n", "        return self.fc(x)\n", "    \n", "    def get_total_latency(self):\n", "        \"\"\"Get total expected latency of the network.\"\"\"\n", "        return (self.layer1.get_latency() + \n", "                self.layer2.get_latency() + \n", "                self.layer3.get_latency())\n", "    \n", "    def get_arch_params(self):\n", "        return [self.layer1.alpha, self.layer2.alpha, self.layer3.alpha]\n", "    \n", "    def get_weight_params(self):\n", "        return [p for n, p in self.named_parameters() if 'alpha' not in n]\n", "\n", "def train_latency_aware(supernet, X_train, y_train, X_val, y_val, \n", "                        latency_target=0.3, epochs=30):\n", "    \"\"\"\n", "    Train with latency constraint in the loss.\n", "    \n", "    Loss = CE_loss + lambda * max(0, latency - target)\n", "    \"\"\"\n", "    weight_opt = torch.optim.SGD(supernet.get_weight_params(), lr=0.01, momentum=0.9)\n", "    arch_opt = torch.optim.Adam(supernet.get_arch_params(), lr=0.001)\n", "    \n", "    criterion = nn.CrossEntropyLoss()\n", "    lambda_latency = 10.0  # Weight for latency penalty\n", "    \n", "    history = {'loss': [], 'latency': [], 'acc': []}\n", "    \n", "    for epoch in range(epochs):\n", "        supernet.train()\n", "        \n", "        # Update weights\n", "        weight_opt.zero_grad()\n", "        loss = criterion(supernet(X_train), y_train)\n", "        loss.backward()\n", "        weight_opt.step()\n", "        \n", "        # Update architecture with latency penalty\n", "        arch_opt.zero_grad()\n", "        ce_loss = criterion(supernet(X_val), y_val)\n", "        latency = supernet.get_total_latency()\n", "        latency_penalty = F.relu(latency - latency_target)\n", "        total_loss = ce_loss + lambda_latency * latency_penalty\n", "        total_loss.backward()\n", "        arch_opt.step()\n", "        \n", "        # Track metrics\n", "        with torch.no_grad():\n", "            acc = (supernet(X_val).argmax(1) == y_val).float().mean().item() * 100\n", "        \n", "        history['loss'].append(ce_loss.item())\n", "        history['latency'].append(latency.item())\n", "        history['acc'].append(acc)\n", "        \n", "        if (epoch + 1) % 10 == 0:\n", "            print(f'Epoch {epoch+1}: Loss={ce_loss.item():.3f}, '\n", "                  f'Latency={latency.item():.3f}ms, Acc={acc:.1f}%')\n", "    \n", "    return history\n", "\n", "# Create data\n", "X_train = torch.randn(200, 3, 32, 32)\n", "y_train = torch.randint(0, 10, (200,))\n", "X_val = torch.randn(100, 3, 32, 32)\n", "y_val = torch.randint(0, 10, (100,))\n", "\n", "print('ðŸ”„ TRAINING LATENCY-AWARE SUPERNET')\n", "print('=' * 50)\n", "print('Target latency: 0.15 ms')\n", "\n", "supernet = LatencyAwareSupernet(latency_table)\n", "history = train_latency_aware(supernet, X_train, y_train, X_val, y_val, \n", "                              latency_target=0.15, epochs=40)"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize training\n", "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n", "\n", "axes[0].plot(history['loss'], color='#3b82f6')\n", "axes[0].set_xlabel('Epoch')\n", "axes[0].set_ylabel('CE Loss')\n", "axes[0].set_title('Classification Loss')\n", "axes[0].grid(True, alpha=0.3)\n", "\n", "axes[1].plot(history['latency'], color='#ef4444')\n", "axes[1].axhline(y=0.15, color='green', linestyle='--', label='Target')\n", "axes[1].set_xlabel('Epoch')\n", "axes[1].set_ylabel('Latency (ms)')\n", "axes[1].set_title('Network Latency')\n", "axes[1].legend()\n", "axes[1].grid(True, alpha=0.3)\n", "\n", "axes[2].plot(history['acc'], color='#22c55e')\n", "axes[2].set_xlabel('Epoch')\n", "axes[2].set_ylabel('Accuracy (%)')\n", "axes[2].set_title('Validation Accuracy')\n", "axes[2].grid(True, alpha=0.3)\n", "\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "# Show final architecture\n", "print('\\nðŸ† DISCOVERED ARCHITECTURE')\n", "print('=' * 50)\n", "for i, layer in enumerate([supernet.layer1, supernet.layer2, supernet.layer3]):\n", "    weights = F.softmax(layer.alpha, dim=0).detach()\n", "    best_idx = weights.argmax().item()\n", "    print(f'Layer {i+1}: {layer.op_names[best_idx]} ({weights[best_idx].item():.1%})')\n", "\n", "print(f'\\nFinal latency: {supernet.get_total_latency().item():.3f} ms')\n", "print(f'Target was: 0.15 ms')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Part 5: Pareto-Optimal Architecture Search"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pareto_search(latency_targets, X_train, y_train, X_val, y_val):\n", "    \"\"\"\n", "    Search for Pareto-optimal architectures.\n", "    Different latency targets give different accuracy-efficiency trade-offs.\n", "    \"\"\"\n", "    pareto_front = []\n", "    \n", "    for target in latency_targets:\n", "        print(f'\\nSearching with latency target: {target} ms')\n", "        \n", "        supernet = LatencyAwareSupernet(latency_table)\n", "        \n", "        # Quick training\n", "        weight_opt = torch.optim.SGD(supernet.get_weight_params(), lr=0.01, momentum=0.9)\n", "        arch_opt = torch.optim.Adam(supernet.get_arch_params(), lr=0.001)\n", "        criterion = nn.CrossEntropyLoss()\n", "        \n", "        for epoch in range(30):\n", "            supernet.train()\n", "            \n", "            weight_opt.zero_grad()\n", "            criterion(supernet(X_train), y_train).backward()\n", "            weight_opt.step()\n", "            \n", "            arch_opt.zero_grad()\n", "            ce_loss = criterion(supernet(X_val), y_val)\n", "            latency = supernet.get_total_latency()\n", "            (ce_loss + 10 * F.relu(latency - target)).backward()\n", "            arch_opt.step()\n", "        \n", "        # Evaluate\n", "        with torch.no_grad():\n", "            acc = (supernet(X_val).argmax(1) == y_val).float().mean().item() * 100\n", "            final_latency = supernet.get_total_latency().item()\n", "        \n", "        # Get architecture\n", "        arch = []\n", "        for layer in [supernet.layer1, supernet.layer2, supernet.layer3]:\n", "            weights = F.softmax(layer.alpha, dim=0).detach()\n", "            arch.append(layer.op_names[weights.argmax().item()])\n", "        \n", "        pareto_front.append({\n", "            'target': target,\n", "            'latency': final_latency,\n", "            'accuracy': acc,\n", "            'architecture': arch\n", "        })\n", "        \n", "        print(f'  Result: {acc:.1f}% accuracy, {final_latency:.3f} ms latency')\n", "        print(f'  Architecture: {arch}')\n", "    \n", "    return pareto_front\n", "\n", "print('ðŸ” PARETO-OPTIMAL ARCHITECTURE SEARCH')\n", "print('=' * 50)\n", "\n", "pareto_results = pareto_search(\n", "    latency_targets=[0.05, 0.10, 0.15, 0.20, 0.30],\n", "    X_train=X_train, y_train=y_train,\n", "    X_val=X_val, y_val=y_val\n", ")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize Pareto front\n", "fig, ax = plt.subplots(figsize=(10, 6))\n", "\n", "latencies = [r['latency'] for r in pareto_results]\n", "accuracies = [r['accuracy'] for r in pareto_results]\n", "\n", "ax.scatter(latencies, accuracies, s=200, c='#3b82f6', zorder=5)\n", "ax.plot(latencies, accuracies, 'b--', alpha=0.5, label='Pareto Front')\n", "\n", "for r in pareto_results:\n", "    ax.annotate(f'{r[\"architecture\"][0][:4]}...', \n", "                (r['latency'], r['accuracy']),\n", "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n", "\n", "ax.set_xlabel('Latency (ms)', fontsize=12)\n", "ax.set_ylabel('Accuracy (%)', fontsize=12)\n", "ax.set_title('ðŸ“Š Pareto Front: Accuracy vs Latency', fontsize=14)\n", "ax.grid(True, alpha=0.3)\n", "ax.legend()\n", "\n", "# Shade dominated region\n", "ax.fill_between([0, max(latencies)*1.1], [min(accuracies)]*2, [0]*2, \n", "                alpha=0.1, color='red', label='Dominated')\n", "\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "print('\\nðŸ“Š PARETO-OPTIMAL ARCHITECTURES')\n", "print('=' * 70)\n", "print(f'{\"Target\":<10} {\"Latency\":<12} {\"Accuracy\":<12} {\"Architecture\":<30}')\n", "print('-' * 70)\n", "for r in pareto_results:\n", "    print(f'{r[\"target\"]:<10.2f} {r[\"latency\"]:<12.3f} {r[\"accuracy\"]:<12.1f} {str(r[\"architecture\"]):<30}')\n", "\n", "print('\\nðŸ’¡ Choose architecture based on your latency budget!')"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('ðŸŽ¯ KEY TAKEAWAYS')\n", "print('=' * 60)\n", "print('\\n1. FLOPs â‰  Latency - hardware efficiency varies by operation')\n", "print('\\n2. Latency lookup tables enable fast hardware-aware search')\n", "print('\\n3. Add latency penalty to loss for constrained optimization')\n", "print('\\n4. Different targets â†’ different accuracy-latency trade-offs')\n", "print('\\n5. Pareto front shows all optimal trade-off points')\n", "print('\\n6. Target-specific architectures beat one-size-fits-all')\n", "print('\\n' + '=' * 60)\n", "print('\\nðŸ“š Next: Knowledge Distillation!')"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8.0"}, "accelerator": "GPU"},
 "nbformat": 4,
 "nbformat_minor": 4
}
